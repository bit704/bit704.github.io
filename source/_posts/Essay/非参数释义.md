---
title: 非参数释义
categories: [Essay]
tags: [CG,Math]
mathjax: true
---

图形学中的“非参数”举例

<!-- more -->

## 出处


即nonparametric，以*Invertible Neural BRDF for Object Inverse Rendering*<sup><a class=n href="#ref1">[1]</a></sup>为例，摘录部分原文如下：

1. *即使我们假设物体的几何形状已知或已经估计，联合估计剩下的反射率和照明的困难仍然存在。关键挑战在于两者之间固有的模糊性，包括颜色和频率<sup><a class=n href="#ref3">[3]</a></sup>。过去的方法依赖于强约束表示，例如，通过采用基于物理或数据驱动的低维参数模型（例如，朗伯和球面谐波）。在这些紧凑的参数模型之上，通常需要强大分析但简单的约束，以更好地调节联合估计，例如真实世界反射率的变化上的高斯混合以及**非参数**照明上的梯度和熵先验<sup><a class=n href="#ref2">[2]</a></sup>。*
2. *理想情况下，我们希望对反射率和照明都使用高维表示，以便估计精度不受其参数形式的限制。挑战因此变为使用常见的高维表示来表达复杂的真实世界反射率，同时驯服真实世界反射率和照明的可变性，以便可以从单个图像中估计它们。**非参数**（即列表）BRDF表示和规则深度生成模型（如生成对抗网络和变分自动编码器）不适用于该任务，因为它们无法在BRDF的角度域中提供用于足够采样的直接方法。*
3. *在本文中，我们介绍了可逆神经BRDF模型（iBRDF），用于从物体外观的单个图像中联合估计反射率和照明。我们表明，将表达能力优于**非参数**表示的可逆可微模型与具有可微渲染的MAP公式相结合，可以实现高效、准确的真实对象逆渲染。我们通过将其双向反射分布函数（BRDF）建模为可逆神经网络，即基于归一化流的非线性变换参数分布<sup><a class=n href="#ref5">[5]</a></sup><sup><a class=n href="#ref6">[6]</a></sup><sup><a class=n href="#ref7">[7]</a></sup>，来利用反射的固有结构。与以往使用低维参数模型的方法形成鲜明对比的是，深度生成神经网络对底层分布不作任何假设，并通过对简单输入分布应用一系列非线性变换来表示BRDF的复杂角度分布。我们将证明，这为我们提供了与**非参数**表示相当或更高的表达能力。此外，模型的可逆性确保了亥姆霍兹相互作用和能量守恒，这对于物理合理性至关重要。此外，尽管我们在本文中没有讨论，但由于iBRDF的双向、可微双向单射，这种可逆性使其也适用于正向渲染应用。我们还表明，这种**非参数**BRDF模型的多个“波瓣”可以组合起来表达真实世界BRDF的复杂颜色和频率特性。此外，为了模拟真实材料反射率变化的内在结构，我们对该生成模型进行条件处理，以提取参数嵌入空间。在简单的参数分布中嵌入BRDF为我们估计反射率提供了强大的先验。*
4. *对于照明，我们采用**非参数**表示，将其建模为角度空间中的点源集合（即，等矩形环境地图）。过去的方法严重依赖于可以转化为分析约束的简单假设，以克服与这种**非参数**照明表示相关的高维复杂性。相反，我们通过利用深度神经网络（即深度图像先验<sup><a class=n href="#ref8">[8]</a></sup>）诱导的结构偏差来约束照明以表示真实的自然环境。我们通过将照明编码为编码器-解码器深度神经网络的输出，并在固定的随机图像输入上优化其参数，来预先设置深度照明。*
5. *综上所述，我们的技术贡献包括*
   - *一个新型BRDF模型，具有**非参数**表示的表达能力和分析分布模型的计算简单性*
   - *一个反射先验，基于嵌入这种新型BRDF模型*
   - *一个照明先验，其利用神经网络结构偏差*
   - *以及基于这些新模型和先验的反射率和照明的完全可微联合估计框架*
6. *为了描述表面点的局部光传输，Nicodemus<sup><a class=n href="#ref9">[9]</a></sup>引入了双向反射分布函数（BRDF），作为入射光和出射光方向的4D反射函数。此后，人们提出了许多参数反射模型，为这一抽象函数提供了解析表达式。Phong<sup><a class=n href="#ref10">[10]</a></sup>和Blinn模型<sup><a class=n href="#ref11">[11]</a></sup>等经验模型为正向渲染提供了极大的简单性，但无法捕捉真实材料的复杂反射率特性，因此不适合进行反射率估计。基于物理的反射模型，如Torrance Sparrow<sup><a class=n href="#ref12">[12]</a></sup>、Cook Torrance<sup><a class=n href="#ref13">[13]</a></sup>和Disney material models<sup><a class=n href="#ref14">[14]</a></sup>严格模拟了光与微表面几何形状的相互作用。虽然这些模型捕捉了具有挑战性的反射特性，如非镜面反射，但其精度仅限于某些类型的材料。*
   *相反，数据驱动的反射率模型通过拟合基函数（例如Zernike多项式<sup><a class=n href="#ref15">[15]</a></sup>和球谐函数<sup><a class=n href="#ref16">[16]</a></sup><sup><a class=n href="#ref3">[3]</a></sup>）或从测量数据中提取此类基<sup><a class=n href="#ref17">[17]</a></sup>来直接建模BRDF。Nishino等人基于新推导的半球指数功率分布介绍了方向统计BRDF模型<sup><a class=n href="#ref18">[18]</a></sup><sup><a class=n href="#ref19">[19]</a></sup>，以半程向量表示表示BRDF，并将其嵌入作为各种逆渲染任务的先验<sup><a class=n href="#ref20">[20]</a></sup><sup><a class=n href="#ref2">[2]</a></sup><sup><a class=n href="#ref21">[21]</a></sup>。Ashikhmin和Premoze<sup><a class=n href="#ref22">[22]</a></sup>使用改进的各向异性Phong拟合测量数据。这些模型的表达能力受到潜在分析分布的限制。Romeiro等人<sup><a class=n href="#ref23">[23]</a></sup>直接使用表格2D各向同性反射分布。尽管**非参数**且具有表达性，但由于其高维数和缺乏可微性，使用此类模型估计反射率仍然具有挑战性。我们表明，我们的可逆神经BRDF模型具有相当数量的参数，在可微和可逆的同时实现了更高的精度。*
7. *现实世界中的材料在反射率方面表现出很大的变化，很难用通用基（如Zernike多项式或Cook-Torrance模型中的解析分布）捕捉到这些变化。**非参数**表示，例如各向同性BRDF的简单3D表格，可以更好地捕捉广泛的变化，同时确保单个BRDF准确表示。另一方面，我们还需要区分关于反射率的误差函数等式1，并评估BRDF的准确可能性。因此，过去的方法倾向于低维参数反射模型，其表达能力有限。我们通过引入基于可逆深度生成神经网络的高维参数反射模型来解决这一基本难题。准确地说，BRDF表示为三维反射分布，该分布由简单的参数分布（例如均匀分布）转换而来。关键特性是，该变换是可逆线性变换的级联，共同导致复杂的**非参数**分布。由此产生的参数化是高维的，具有与**非参数**表格一样多的参数，因此具有极强的表达能力，但可微，也可以有效地进行采样和评估。*

对于1中提到的非参数照明，摘录原文<sup><a class=n href="#ref2">[2]</a></sup>如下：

> 许多方法假设可以使用低阶参数模型（如球谐函数）或少量点光源对自然照明进行建模。当反射率模型不是朗伯模型时，这些模型无法准确预测场景辐照度。为了模拟真实场景，需要一个表示入射照明球体的全色**非参数**照明模型。
>
> 我们的照明模型是入射照明场的**非参数**表示。**非参数**模型允许很强的表达能力，为了减少解空间，这些表达能力必须受到约束。我们使用几个先验来实现这一点。首先，我们采用Lombardi和Nishino<sup><a class=n href="#ref4">[4]</a></sup>引入的熵先验，该先验建模了照明与物体反射率相互作用导致的熵损失。我们还利用自然图像统计先验，鼓励恢复合理的自然照明环境。

非参数是这个[意思](https://zhuanlan.zhihu.com/p/350307389)，即统计学上的非参数。

考虑具有形式$Y=g(X)+W$的模型，该模型涉及两个随机变量$X$和$Y$，其中$W$是零均值噪声，$g$是需要估计的未知函数。这类问题，未知目标（比如这里的函数g）是不能表述为固定数目的参数，称为**非参数**统计推断问题。



## 参考文献

<a name="ref1">[1] Chen Z, Nobuhara S, Nishino K. Invertible neural BRDF for object inverse rendering[J]. IEEE Transactions on Pattern Analysis and Machine Intelligence, 2021.</a>

<a name="ref2">[2] Lombardi S, Nishino K. Reflectance and illumination recovery in the wild[J]. IEEE transactions on pattern analysis and machine intelligence, 2015, 38(1): 129-141.</a>

<a name="ref3">[3] Ramamoorthi R, Hanrahan P. A signal-processing framework for inverse rendering[C]//Proceedings of the 28th annual conference on Computer graphics and interactive techniques. 2001: 117-128.</a>

<a name="ref4">[4] Lombardi S, Nishino K. Reflectance and natural illumination from a single image[C]//European Conference on Computer Vision. Springer, Berlin, Heidelberg, 2012: 582-595.</a>

<a name="ref5">[5] Müller T, McWilliams B, Rousselle F, et al. Neural importance sampling[J]. ACM Transactions on Graphics (TOG), 2019, 38(5): 1-19.</a>

<a name="ref6">[6] Tabak E G, Turner C V. A family of nonparametric density estimation algorithms[J]. Communications on Pure and Applied Mathematics, 2013, 66(2): 145-164.</a>

<a name="ref7">[7] Tabak E G, Vanden-Eijnden E. Density estimation by dual ascent of the log-likelihood[J]. Communications in Mathematical Sciences, 2010, 8(1): 217-233.</a>

<a name="ref8">[8] Ulyanov D, Vedaldi A, Lempitsky V. Deep image prior[C]//Proceedings of the IEEE conference on computer vision and pattern recognition. 2018: 9446-9454.</a>

<a name="ref9">[9] Nicodemus F E, Richmond J C, Hsia J J, et al. Geometric Considerations and Nomenclaturefor Reflectance[J]. US Dept. of Commerce, Washington, DC, NBS Monograph, 1977, 160</a>

<a name="ref10">[10] Phong B T. Illumination for computer generated pictures[J]. Communications of the ACM, 1975, 18(6): 311-317.</a>

<a name="ref11">[11] Blinn J F. Models of light reflection for computer synthesized pictures[C]//Proceedings of the 4th annual conference on Computer graphics and interactive techniques. 1977: 192-198.</a>

<a name="ref12">[12] Torrance K E, Sparrow E M. Theory for off-specular reflection from roughened surfaces[J]. Josa, 1967, 57(9): 1105-1114.</a>

<a name="ref13">[13] Cook R L, Torrance K E. A reflectance model for computer graphics[J]. ACM Transactions on Graphics (ToG), 1982, 1(1): 7-24.</a>

<a name="ref14">[14] Burley B, Studios W D A. Physically-based shading at disney[C]//ACM SIGGRAPH. vol. 2012, 2012, 2012: 1-7.</a>

<a name="ref15">[15] Koenderink J J, Doorn A J, Stavridi M. Bidirectional reflection distribution function expressed in terms of surface scattering modes[C]//European Conference on Computer Vision. Springer, Berlin, Heidelberg, 1996: 28-39. </a>

<a name="ref16">[16] Basri R, Jacobs D, Kemelmacher I. Photometric stereo with general, unknown lighting[J]. International Journal of computer vision, 2007, 72(3): 239-257.</a>

<a name="ref17">[17] Matusik W. A data-driven reflectance model[D]. Massachusetts Institute of Technology, 2003. </a>

<a name="ref18">[18] Nishino K. Directional statistics BRDF model[C]//2009 IEEE 12th International Conference on Computer Vision. IEEE, 2009: 476-483.</a>

<a name="ref19">[19] Nishino K, Lombardi S. Directional statistics-based reflectance model for isotropic bidirectional reflectance distribution functions[J]. JOSA A, 2011, 28(1): 8-18.</a>

<a name="ref20">[20] Lombardi S, Nishino K. Radiometric scene decomposition: Scene reflectance, illumination, and geometry from rgb-d images[C]//2016 fourth international conference on 3d vision (3dv). IEEE, 2016: 305-313.</a>

<a name="ref21">[21] Oxholm G, Nishino K. Shape and reflectance estimation in the wild[J]. IEEE transactions on pattern analysis and machine intelligence, 2015, 38(2): 376-389.</a>

<a name="ref22">[22] Ashikhmin M, Premoze S. Distribution-based brdfs[J]. Unpublished Technical Report, University of Utah, 2007, 2: 6.</a>

<a name="ref23">[23] Romeiro F, Vasilyev Y, Zickler T. Passive reflectometry[C]//European Conference on Computer Vision. Springer, Berlin, Heidelberg, 2008: 859-872.</a>

